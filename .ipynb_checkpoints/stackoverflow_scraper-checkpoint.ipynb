{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17e2858f-a82f-4a77-ac4e-11354595fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pymongo\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "def stackoverflow_scraper(tag, keyword, db_name, user_agent, uri, fromDate, toDate):\n",
    "    \"\"\"\n",
    "    This function searches for Stack Overflow questions tagged with a certain tag and saves the information to a MongoDB database.\n",
    "    Parameters:\n",
    "        tag(String) = tag name\n",
    "        keyword(String) = keyword to search in titles and body of questions\n",
    "        db_name(String) = what you want the database called\n",
    "        user_agent(String) = user agent name\n",
    "        uri(String) = The link to the MongoDB database \n",
    "        fraomDate(Datetime) = What date to start scrapping \n",
    "        toDate(Datetime) = The end date to end scrapping\n",
    "    \"\"\"\n",
    "    # Set the base URL for the API\n",
    "    base_url = \"https://api.stackexchange.com/2.3/\"\n",
    "\n",
    "    # Setting the parameters for the request\n",
    "    params = {\n",
    "        \"site\": \"stackoverflow\",\n",
    "        \"tagged\": tag,\n",
    "        \"filter\": \"withbody\",\n",
    "        \"pagesize\": 100,\n",
    "        \"fromdate\": fromDate,\n",
    "        \"todate\": toDate,\n",
    "        \"answers\": \"true\"\n",
    "    }\n",
    "\n",
    "\n",
    "    # Set the headers for the request\n",
    "    headers = {\n",
    "        \"User-Agent\": user_agent\n",
    "    }\n",
    "\n",
    "    # Make the request to the API\n",
    "    response = requests.get(f\"{base_url}search\", params=params, headers=headers)\n",
    "\n",
    "    # Get the JSON data from the response\n",
    "    data = response.json()\n",
    "\n",
    "    # Name of the database\n",
    "    client = pymongo.MongoClient(uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[\"StackOverflowPosts\"]\n",
    "    collection_users = db[\"StackOverflowUsers\"]\n",
    "        \n",
    "    # Loop through the questions and save them to the database\n",
    "    for question in data[\"items\"]:\n",
    "        # If there is a duplicate question_id then skip over.\n",
    "        if collection.find_one({\"question_id\": question[\"question_id\"]}):\n",
    "            continue \n",
    "            \n",
    "        # Timestamp formatting\n",
    "        timestamp = datetime.datetime.utcfromtimestamp(question[\"creation_date\"])\n",
    "        formatted_timestamp = timestamp.isoformat()\n",
    "        print(question)\n",
    "\n",
    "        # Question dictionary to be added to the database\n",
    "        question_dict = {\n",
    "            \"question_id\": question[\"question_id\"],\n",
    "            \"title\": question[\"title\"],\n",
    "            \"body\": question[\"body\"],\n",
    "            \"score\": question[\"score\"],\n",
    "            \"tags\": question[\"tags\"],\n",
    "            \"view_count\": question[\"view_count\"],\n",
    "            \"answer_count\": question[\"answer_count\"],\n",
    "            \"timestamp\": formatted_timestamp,\n",
    "        }\n",
    "        collection.insert_one(question_dict)\n",
    "\n",
    "        # User dictionary to be added to the database\n",
    "        user_id = question[\"owner\"][\"user_id\"]\n",
    "        user_response = requests.get(f\"{base_url}users/{user_id}\", params={\"site\": \"stackoverflow\"}, headers=headers)\n",
    "        user_data = user_response.json()\n",
    "        \n",
    "        # If there is a duplicate user_id then skip over.\n",
    "        if collection.find_one({\"user_id\":user_id,}):\n",
    "            continue\n",
    "            \n",
    "        user_dict = {\n",
    "            \"username\": user_data[\"items\"][0].get(\"display_name\", \"N/A\"),\n",
    "            \"user_id\": user_id,\n",
    "            \"location\": user_data[\"items\"][0].get(\"location\", \"N/A\"),\n",
    "            \"reputation\": user_data[\"items\"][0].get(\"reputation\", \"N/A\"),\n",
    "            \"badges\": user_data[\"items\"][0].get(\"badge_counts\", \"N/A\"),\n",
    "            \"experience\": user_data[\"items\"][0].get(\"creation_date\", \"N/A\"),\n",
    "            \"privileges\": user_data[\"items\"][0].get(\"privileges\"),\n",
    "            \"account_id\": user_data[\"items\"][0].get(\"account_id\", \"N/A\"),\n",
    "            \"is_employee\": user_data[\"items\"][0].get(\"is_employee\", \"N/A\"),\n",
    "            \"last_access_date\": user_data[\"items\"][0].get(\"last_access_date\", \"N/A\"),\n",
    "            \"reputation_change_year\": user_data[\"items\"][0].get(\"reputation_change_year\", \"N/A\"),\n",
    "            \"reputation_change_quarter\": user_data[\"items\"][0].get(\"reputation_change_quarter\", \"N/A\"),\n",
    "            \"reputation_change_month\": user_data[\"items\"][0].get(\"reputation_change_month\", \"N/A\"),\n",
    "            \"reputation_change_week\": user_data[\"items\"][0].get(\"reputation_change_week\", \"N/A\"),\n",
    "            \"reputation_change_day\": user_data[\"items\"][0].get(\"reputation_change_day\", \"N/A\"),\n",
    "            \"user_type\": user_data[\"items\"][0].get(\"user_type\", \"N/A\"),\n",
    "            \"link\": user_data[\"items\"][0].get(\"link\", \"N/A\"),\n",
    "            \"profile_image\": user_data[\"items\"][0].get(\"profile_image\", \"N/A\")\n",
    "        }\n",
    "\n",
    "        collection_users.insert_one(user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c8be252-fa62-4a09-854a-3bbfdd5ad0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error_id': 502, 'error_message': 'too many requests from this IP, more requests available in 76778 seconds', 'error_name': 'throttle_violation'}\n"
     ]
    }
   ],
   "source": [
    "tag = \"php\"\n",
    "keyword = None\n",
    "\n",
    "db_name = \"StackOverFlowData\"\n",
    "uri = \"mongodb+srv://testbot:king@cluter1.kov9r66.mongodb.net/?retryWrites=true&w=majority\"\n",
    "username = \"Da16King\"\n",
    "fromDate = datetime.datetime(2020,1,1)\n",
    "toDate = datetime.datetime(2023,3,23)\n",
    "\n",
    "stackoverflow_scraper(tag,keyword, db_name , username, uri, fromDate, toDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f6b6c-5882-4214-aee9-5338108960ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
