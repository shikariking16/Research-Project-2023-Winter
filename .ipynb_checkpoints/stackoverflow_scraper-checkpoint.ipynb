{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17e2858f-a82f-4a77-ac4e-11354595fdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pymongo\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "def stackoverflow_scraper(tag, keyword, db_name, user_agent, uri, fromDate, toDate):\n",
    "    \"\"\"\n",
    "    This function searches for Stack Overflow questions tagged with a certain tag and saves the information to a MongoDB database.\n",
    "    Parameters:\n",
    "        tag(String) = tag name\n",
    "        keyword(String) = keyword to search in titles and body of questions\n",
    "        db_name(String) = what you want the database called\n",
    "        user_agent(String) = user agent name\n",
    "        uri(String) = The link to the MongoDB database \n",
    "        fraomDate(Datetime) = What date to start scrapping \n",
    "        toDate(Datetime) = The end date to end scrapping\n",
    "    \"\"\"\n",
    "    # Set the base URL for the API\n",
    "    base_url = \"https://api.stackexchange.com/2.3/\"\n",
    "\n",
    "    # Setting the parameters for the request\n",
    "    params = {\n",
    "        \"site\": \"stackoverflow\",\n",
    "        \"tagged\": tag,\n",
    "        \"filter\": \"withbody\",\n",
    "        \"pagesize\": 100,\n",
    "        \"fromdate\": fromDate,\n",
    "        \"todate\": toDate,\n",
    "        \"answers\": \"true\"\n",
    "    }\n",
    "\n",
    "    # Set the headers for the request\n",
    "    headers = {\n",
    "        \"User-Agent\": user_agent\n",
    "    }\n",
    "\n",
    "    # Make the request to the API\n",
    "    response = requests.get(f\"{base_url}search\", params=params, headers=headers)\n",
    "\n",
    "    # Get the JSON data from the response\n",
    "    data = response.json()\n",
    "    # Name of the database\n",
    "    client = pymongo.MongoClient(uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[\"StackOverflowPosts\"]\n",
    "    collection_users = db[\"StackOverflowUsers\"]\n",
    "    \n",
    "    # Error check if there are too many requests for the API\n",
    "    if data.get('error_id') == 502 and data.get('error_name') == 'throttle_violation':\n",
    "        assert False, f\"API rate limit reached. Try retry in {data.get('error_message').split()[-2]} seconds.\"\n",
    "\n",
    "    \n",
    "    # Loop through the questions and save them to the database\n",
    "    for question in data[\"items\"]:\n",
    "        # If there is a duplicate question_id then skip over.\n",
    "        if collection.find_one({\"question_id\": question[\"question_id\"]}):\n",
    "            continue \n",
    "            \n",
    "        # Timestamp formatting\n",
    "        timestamp = datetime.datetime.utcfromtimestamp(question[\"creation_date\"])\n",
    "        formatted_timestamp = timestamp.isoformat()\n",
    "\n",
    "        # Question dictionary to be added to the database\n",
    "        question_dict = {\n",
    "            \"question_id\": question[\"question_id\"],\n",
    "            \"title\": question[\"title\"],\n",
    "            \"body\": question[\"body\"],\n",
    "            \"score\": question[\"score\"],\n",
    "            \"tags\": question[\"tags\"],\n",
    "            \"view_count\": question[\"view_count\"],\n",
    "            \"answer_count\": question[\"answer_count\"],\n",
    "            \"timestamp\": formatted_timestamp,\n",
    "        }\n",
    "        collection.insert_one(question_dict)\n",
    "\n",
    "        # User dictionary to be added to the database\n",
    "        user_id = question[\"owner\"][\"user_id\"]\n",
    "        user_response = requests.get(f\"{base_url}users/{user_id}\", params={\"site\": \"stackoverflow\"}, headers=headers)\n",
    "        user_data = user_response.json()\n",
    "        # If there is a duplicate user_id then skip over.\n",
    "        if collection.find_one({\"user_id\":user_id,}):\n",
    "            continue\n",
    "            \n",
    "        user_dict = {\n",
    "            \"username\": user_data[\"items\"][0].get(\"display_name\", \"N/A\"),\n",
    "            \"user_id\": user_id,\n",
    "            \"location\": user_data[\"items\"][0].get(\"location\", \"N/A\"),\n",
    "            \"question_count\":user_questions(user_id),\n",
    "            \"answer_count\":user_answers(user_id),\n",
    "            \"reputation\": user_data[\"items\"][0].get(\"reputation\", \"N/A\"),\n",
    "            \"badges\": user_data[\"items\"][0].get(\"badge_counts\", \"N/A\"),\n",
    "            \"experience\": user_data[\"items\"][0].get(\"creation_date\", \"N/A\"),\n",
    "            \"privileges\": user_data[\"items\"][0].get(\"privileges\"),\n",
    "            \"account_id\": user_data[\"items\"][0].get(\"account_id\", \"N/A\"),\n",
    "            \"is_employee\": user_data[\"items\"][0].get(\"is_employee\", \"N/A\"),\n",
    "            \"last_access_date\": user_data[\"items\"][0].get(\"last_access_date\", \"N/A\"),\n",
    "            \"reputation_change_year\": user_data[\"items\"][0].get(\"reputation_change_year\", \"N/A\"),\n",
    "            \"reputation_change_quarter\": user_data[\"items\"][0].get(\"reputation_change_quarter\", \"N/A\"),\n",
    "            \"reputation_change_month\": user_data[\"items\"][0].get(\"reputation_change_month\", \"N/A\"),\n",
    "            \"reputation_change_week\": user_data[\"items\"][0].get(\"reputation_change_week\", \"N/A\"),\n",
    "            \"reputation_change_day\": user_data[\"items\"][0].get(\"reputation_change_day\", \"N/A\"),\n",
    "            \"user_type\": user_data[\"items\"][0].get(\"user_type\", \"N/A\"),\n",
    "            \"link\": user_data[\"items\"][0].get(\"link\", \"N/A\"),\n",
    "            \"profile_image\": user_data[\"items\"][0].get(\"profile_image\", \"N/A\")\n",
    "        }\n",
    "\n",
    "        collection_users.insert_one(user_dict)\n",
    "\n",
    "def user_answers(user_id):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        user_id (String): user_id of the user to get the number of answers they asked\n",
    "\n",
    "    Returns:\n",
    "        int: # of questions\n",
    "    \"\"\"\n",
    "    url = f\"https://api.stackexchange.com//2.3/users/{user_id}/answers?order=desc&sort=activity&site=stackoverflow&filter=total\"\n",
    "\n",
    "    #API request\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # data = the json response\n",
    "    data = response.json()\n",
    "\n",
    "    # Return the answer count of a user\n",
    "    answer_count = data['total']\n",
    "    return answer_count\n",
    "\n",
    "def user_questions(user_id):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        user_id (String): user_id of the user to get the number of questions they asked\n",
    "\n",
    "    Returns:\n",
    "        int: # of answers\n",
    "    \"\"\"\n",
    "    url = f\"https://api.stackexchange.com//2.3/users/{user_id}/questions?order=desc&sort=activity&site=stackoverflow&filter=total\"\n",
    "\n",
    "    #API request\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # data = the json response\n",
    "    data = response.json()\n",
    "\n",
    "    # returning the question count for a given user\n",
    "    question_count = data['total']\n",
    "    return question_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "159dc24f-143e-48db-82f8-34670569ce88",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "API rate limit reached. Try retry in 85103 seconds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m fromDate \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime(\u001b[38;5;241m2020\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m toDate \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime(\u001b[38;5;241m2023\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mstackoverflow_scraper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkeyword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musername\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfromDate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoDate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 50\u001b[0m, in \u001b[0;36mstackoverflow_scraper\u001b[0;34m(tag, keyword, db_name, user_agent, uri, fromDate, toDate)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Error check if there are too many requests for the API\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_id\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m502\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_name\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthrottle_violation\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI rate limit reached. Try retry in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_message\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Loop through the questions and save them to the database\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# If there is a duplicate question_id then skip over.\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: API rate limit reached. Try retry in 85103 seconds."
     ]
    }
   ],
   "source": [
    "tag = \"php\"\n",
    "keyword = None\n",
    "\n",
    "db_name = \"StackOverFlowData\"\n",
    "uri = \"mongodb+srv://testbot:king@cluter1.kov9r66.mongodb.net/?retryWrites=true&w=majority\"\n",
    "username = \"Da16King\"\n",
    "fromDate = datetime.datetime(2020,1,1)\n",
    "toDate = datetime.datetime(2023,4,4)\n",
    "\n",
    "stackoverflow_scraper(tag,keyword, db_name , username, uri, fromDate, toDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f89445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
