{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3254206-3072-450b-89d0-26f1f0531244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pymongo\n",
    "import datetime\n",
    "\n",
    "def reddit_subreddit_scraper(sub_reddit, db_name, client_id, client_secret, user_agent,uri,start_date, end_date):\n",
    "    \"\"\"\n",
    "    This function seaches a subReddit on reddit and adds the information to a MongoDB database.\n",
    "    Parameters:\n",
    "        sub_reddit(String) = sub reddit name\n",
    "        db_name(String) = what you want the database called\n",
    "        client_id(String) = the client ID given from Reddit API\n",
    "        client_secret(String) = secret given by Reddit API\n",
    "        user_agent(String) = username of the user\n",
    "        uri(String) = The link to the MongoDB database \n",
    "        start_date(datetime)= The earliest posts created that can be collected\n",
    "        end_date(datetime) = The latest a post can be collected\n",
    "    \"\"\"\n",
    "    # If the date is not specified then starts in 2005, when Reddit was founded and ends on the current day.\n",
    "    if start_date is None:\n",
    "        start_date = datetime.datetime(2005, 1, 1)\n",
    "    if end_date is None:\n",
    "        end_date = datetime.today()\n",
    "    \n",
    "    # Information for praw\n",
    "    reddit = praw.Reddit(\n",
    "        client_id = client_id,\n",
    "        client_secret = client_secret,\n",
    "        user_agent = user_agent\n",
    "    )\n",
    "\n",
    "    # The name of the MongoDB \n",
    "    client = pymongo.MongoClient(uri)\n",
    "    \n",
    "    # Name of the subreddit to search for\n",
    "    subRedditName = sub_reddit\n",
    "    \n",
    "    # Name of the database\n",
    "    db = client[db_name]\n",
    "    \n",
    "    # Names of the collections\n",
    "    collection = db[\"RedditPosts\"]\n",
    "    collection_comments = db[\"RedditComments\"]\n",
    "    \n",
    "    # Loop for searching reddit, can change the limit to a whole number to limit the amount of posts per search\n",
    "    # However it is currently no limit which will scan everypost in the subreddit\n",
    "    for post in reddit.subreddit(subRedditName).top(limit=None):\n",
    "\n",
    "        # Check if post already exists in the database\n",
    "        # Skip this post if it already exists in the database\n",
    "        if collection.find_one({\"post_url\": f\"https://www.reddit.com{post.permalink}\"}):\n",
    "            continue \n",
    "\n",
    "        # Timestamp formatting\n",
    "        timestamp = datetime.datetime.utcfromtimestamp(post.created_utc)\n",
    "\n",
    "        # Skip the post if it was created after or before the specfiied dates\n",
    "        if timestamp > end_date or timestamp < start_date:\n",
    "            continue\n",
    "        \n",
    "        # Formats the timestamp into the correct format\n",
    "        formatted_timestamp = timestamp.isoformat()\n",
    "\n",
    "        # Post dictionary to be added to the database\n",
    "        post_dict = {\n",
    "            \"title\": post.title,\n",
    "            \"post_id\": post.id,\n",
    "            \"author\": post.author.name if post.author else 'N/A',\n",
    "            \"num_comments\": post.num_comments,\n",
    "            \"score\": post.score,\n",
    "            \"attachment_file\": post.url,\n",
    "            \"timestamp\": formatted_timestamp,\n",
    "            \"subreddit_name\": subRedditName,\n",
    "            \"post_url\": f\"https://www.reddit.com{post.permalink}\"\n",
    "        }\n",
    "        collection.insert_one(post_dict)\n",
    "        # Created a set so that duplicates could not be added\n",
    "        comment_set = set()\n",
    "\n",
    "        # Scrapping the comment and if the author is deleted account then put N/A\n",
    "        for comment in post.comments.list():\n",
    "            if collection_comments.find_one({\"id\": comment.id}):\n",
    "                continue\n",
    "\n",
    "            if isinstance(comment, praw.models.Comment):\n",
    "                comment_dict = {\n",
    "                    \"id\": comment.id,\n",
    "                    \"post_id\": post.id,\n",
    "                    \"author\": comment.author.name if comment.author else 'N/A',\n",
    "                    \"score\": comment.score,\n",
    "                    \"num_replies\": len(comment.replies),\n",
    "                    \"text\": comment.body,\n",
    "                    \"subreddit_name\": subRedditName,\n",
    "                    \"timestamp\": datetime.datetime.utcfromtimestamp(comment.created_utc).isoformat(),\n",
    "                }\n",
    "\n",
    "            # Skip the comment if it was created after or before the specified dates\n",
    "            comment_timestamp = datetime.datetime.utcfromtimestamp(comment.created_utc)\n",
    "            if comment_timestamp > end_date or comment_timestamp < start_date:\n",
    "                continue\n",
    "            \n",
    "            # Convert the set back into a tuple in order to be added to the database.\n",
    "            comment_tuple = tuple(comment_dict.items())\n",
    "            comment_set.add(comment_tuple)\n",
    "\n",
    "        comment_list = [dict(comment_tuple) for comment_tuple in comment_set]\n",
    "        collection_comments.insert_many(comment_list)\n",
    "        \n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53cb0c85-efaf-459a-92f2-e93565d61e95",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m start_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime(\u001b[38;5;241m2020\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m17\u001b[39m)\n\u001b[1;32m     11\u001b[0m end_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime(\u001b[38;5;241m2023\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m17\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m reddit_subreddit_scraper(sub_reddit, db_name, \u001b[43mclient_id\u001b[49m, client_secret, user_agent,uri,start_date, end_date)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client_id' is not defined"
     ]
    }
   ],
   "source": [
    "sub_reddit = \"ChatGPT\"\n",
    "\n",
    "db_name = \"RedditData\"\n",
    "client_id = \"XXJgyOD5LF7dxRTGedxliQ\"\n",
    "client_secret = \"4W2SxwrOIz6xJWNz4ePVTX2_GwF2BA\"\n",
    "user_agent = \"Bombe_Cerise\"\n",
    "uri = \"mongodb+srv://testbot:king@cluter1.kov9r66.mongodb.net/?retryWrites=true&w=majority\"\n",
    "\n",
    "# Which dates to start the scrapper for posts and comments and which date to end it\n",
    "start_date = datetime.datetime(2020, 3, 17)\n",
    "end_date = datetime.datetime(2023, 3, 17)\n",
    "\n",
    "reddit_subreddit_scraper(sub_reddit, db_name, client_id, client_secret, user_agent,uri,start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e94474-a108-41ce-88be-4a329283bbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
